{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750552ca",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Grid-Search\" data-toc-modified-id=\"Grid-Search-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Grid Search</a></span></li><li><span><a href=\"#Best-params-result\" data-toc-modified-id=\"Best-params-result-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Best params result</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd33e98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T05:53:53.849688Z",
     "start_time": "2021-12-09T05:53:53.838689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n",
       "print(nb_name)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n",
    "print(nb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c10242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T05:53:58.999036Z",
     "start_time": "2021-12-09T05:53:53.851689Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from clustering_utils import *\n",
    "from eda_utils import *\n",
    "from myutils_V6 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff5ea42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T05:54:00.524037Z",
     "start_time": "2021-12-09T05:53:59.001039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "may use cols: \n",
      " ['global_index', 'doc_path', 'label', 'reply', 'reference_one', 'reference_two', 'tag_reply', 'tag_reference_one', 'tag_reference_two', 'Subject', 'From', 'Lines', 'Organization', 'contained_emails', 'long_string', 'text', 'error_message']\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data()\n",
    "train, upsampling_info = upsampling_train(train)\n",
    "\n",
    "train_text, train_label = train_augmentation(train, select_comb=None)\n",
    "test_text, test_label = test['text'], test['label']\n",
    "\n",
    "# test_text = test_text.apply(lambda x: normal_string(x))\n",
    "# train_text = train_text.apply(lambda x: normal_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38415f34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T05:54:00.538034Z",
     "start_time": "2021-12-09T05:54:00.526038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11813,)\n",
      "(7761,)\n",
      "(11813,)\n",
      "(7761,)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "### label mapper\n",
    "####################################\n",
    "labels = sorted(train_label.unique())\n",
    "label_mapper = dict(zip(labels, range(len(labels))))\n",
    "train_label = train_label.map(label_mapper)\n",
    "test_label = test_label.map(label_mapper)\n",
    "y_train = train_label\n",
    "y_test = test_label\n",
    "\n",
    "print(train_text.shape)\n",
    "print(test_text.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4ac02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T04:06:45.619843Z",
     "start_time": "2021-12-09T04:06:45.615842Z"
    }
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184845f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:53.880Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = \"f1_macro\"\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
    "parameters = {'tfidf__min_df': [1, 3, 5], 'tfidf__stop_words': [None, 'english'], 'tfidf__use_idf': [True, False], 'tfidf__binary': [True, False],\n",
    "              'clf__alpha': [0.6, 0.8, 1]}\n",
    "gs_clf = GridSearchCV(text_clf, scoring=metric, param_grid=parameters, cv=4)\n",
    "gs_clf = gs_clf.fit(train_text, y_train)\n",
    "\n",
    "for param_name in gs_clf.best_params_:\n",
    "    print(\"{0}:\\t{1}\".format(param_name, gs_clf.best_params_[param_name]))\n",
    "\n",
    "print(\"best f1 score: {:.3f}\".format(gs_clf.best_score_))\n",
    "cv_results = pd.DataFrame(gs_clf.cv_results_)\n",
    "cv_results.to_excel(f\"NB_cv_result_{nb_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c03414",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:53.881Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = \"f1_macro\"\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])\n",
    "parameters = {'tfidf__min_df': [1, 3, 5], 'tfidf__stop_words': [None, 'english'], 'tfidf__use_idf': [True, False], 'tfidf__binary': [True, False],\n",
    "             'clf__penalty':['l2'], 'clf__C':[1,2,3]}\n",
    "gs_clf = GridSearchCV(text_clf, scoring=metric, param_grid=parameters, cv=4)\n",
    "gs_clf = gs_clf.fit(train_text, y_train)\n",
    "\n",
    "for param_name in gs_clf.best_params_:\n",
    "    print(\"{0}:\\t{1}\".format(param_name, gs_clf.best_params_[param_name]))\n",
    "\n",
    "print(\"best f1 score: {:.3f}\".format(gs_clf.best_score_))\n",
    "cv_results = pd.DataFrame(gs_clf.cv_results_)\n",
    "cv_results.to_excel(f\"SVC_cv_result_{nb_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a9ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783b6bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fc184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca8905a",
   "metadata": {},
   "source": [
    "# Best params result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf65c2a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:53.918Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, word_to_idx, tfidf_vect = tfidf_vectorizer(train_text, test_text, min_df=3, max_df=0.001)\n",
    "X_train, X_test, word_to_idx, tfidf_vect = count_vectorizer(train_text, test_text, min_df=3, max_df=0.95)\n",
    "# tfidf_vectorizer(train_text, test_text, min_df=2, max_df=100)\n",
    "# X_train, transform_mapper = dimension_reduction(X_train, out_dim=500)\n",
    "# X_test = transform_mapper.transform(X_test)\n",
    "\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('X_test.shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9fa6c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:53.919Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(penalty=\"l2\", multi_class='ovr', C=1.0, dual=True, max_iter=5000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_true = y_test, y_pred=pred, target_names=labels))\n",
    "\n",
    "##########################################\n",
    "## CV shows the stable result\n",
    "##########################################\n",
    "cv_metrics = [\"precision_macro\",\"accuracy\", \"f1_macro\"]\n",
    "cv = cross_validate(clf, X_train, y_train,scoring=cv_metrics, cv=4, return_train_score=True)\n",
    "cv = pd.DataFrame(cv)\n",
    "f1 = cv['test_f1_macro'].mean()\n",
    "print(\"cv average f1 macro: \", f1)\n",
    "\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046a488",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:53.920Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_true = y_test, y_pred=pred, target_names=labels))\n",
    "\n",
    "\n",
    "##########################################\n",
    "## CV shows the stable result\n",
    "##########################################\n",
    "cv_metrics = [\"precision_macro\",\"accuracy\", \"f1_macro\"]\n",
    "cv = cross_validate(clf, X_train, y_train,scoring=cv_metrics, cv=4, return_train_score=True)\n",
    "cv = pd.DataFrame(cv)\n",
    "f1 = cv['test_f1_macro'].mean()\n",
    "print(\"cv average f1 macro: \", f1)\n",
    "\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d856b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ada9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16aa04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575629d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ad48c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bb8d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e95ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f962f640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915afb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f2543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e8150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a39f11",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:53.931Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "p = (clf.predict_proba(test_dtm))[:, 1] \n",
    "p_binary = clf.predict(test_dtm)\n",
    "\n",
    "p_label = 2\n",
    "fpr, tpr, thresholds = roc_curve(test_y, p, pos_label=p_label)\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "pre, rec, thresholds = precision_recall_curve(test_y, p, pos_label=p_label)\n",
    "\n",
    "# calculate auc\n",
    "prc_score = auc(rec, pre)\n",
    "\n",
    "if show_plots:\n",
    "\n",
    "    print(classification_report(test_y, p_binary))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('AUC')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(rec, pre, color='darkorange', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('PRC')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(\"AUC: {:.2%}, PRC: {:.2%}\".format(auc_score, prc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3c1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa749c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68edec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4939f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:53.935Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd98899",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:53.936Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, roc_curve, auc, precision_recall_curve\n",
    "# mapping from integer feature name to original token string\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Feature reduction with Kbest features based on chi2 score\n",
    "ch2 = SelectKBest(chi2, k=50000)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)\n",
    "if feature_names:\n",
    "    # keep selected feature names\n",
    "    feature_names = [feature_names[i] for i in ch2.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdba24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d293acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a7085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22b10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e896cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T03:48:57.019131Z",
     "start_time": "2021-12-09T03:48:57.017130Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cfa988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
