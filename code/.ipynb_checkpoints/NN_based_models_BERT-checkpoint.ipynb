{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d89dfe26",
   "metadata": {
    "id": "d89dfe26",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Colab\" data-toc-modified-id=\"Colab-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Colab</a></span></li><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loading</a></span><ul class=\"toc-item\"><li><span><a href=\"#extra-one-hot-features\" data-toc-modified-id=\"extra-one-hot-features-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>extra one-hot features</a></span></li><li><span><a href=\"#extra-keywords\" data-toc-modified-id=\"extra-keywords-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>extra keywords</a></span></li></ul></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>BERT</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c43715",
   "metadata": {
    "id": "05c43715"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#TextCNN\" data-toc-modified-id=\"TextCNN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TextCNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#notes:\" data-toc-modified-id=\"notes:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>notes:</a></span></li></ul></li><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>LSTM</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f5360",
   "metadata": {},
   "source": [
    "# Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be328c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T02:09:53.148780Z",
     "start_time": "2021-12-10T02:09:53.144780Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85be328c",
    "outputId": "9e08d25f-a7f3-4379-e52f-7c42529fd08a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
      "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.16)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.4)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/MyDrive/Text-Classification/code\")\n",
    "!pip install pyLDAvis\n",
    "!pip install gensim\n",
    "!pip install pandas==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c39454",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8c845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T02:09:58.418780Z",
     "start_time": "2021-12-10T02:09:53.150782Z"
    },
    "id": "7ea8c845"
   },
   "outputs": [],
   "source": [
    "from classification_utils import *\n",
    "from clustering_utils import *\n",
    "from eda_utils import *\n",
    "from nn_utils_keras import *\n",
    "from feature_engineering_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f27bb1",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88921e6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-10T02:11:34.258Z"
    },
    "id": "f88921e6"
   },
   "outputs": [],
   "source": [
    "train, test = load_data(only_stem_voc=True)\n",
    "# train, upsampling_info = upsampling_train(train)\n",
    "\n",
    "train_text, train_label = train_augmentation(train, select_comb=None)\n",
    "test_text, test_label = test['text'], test['label']\n",
    "\n",
    "# test_text = test_text.apply(lambda x: extract_stem_voc(x))\n",
    "# train_text = train_text.apply(lambda x: extract_stem_voc(x))\n",
    "# train_text.to_csv(\"stem_voc_train.csv\")\n",
    "# test_text.to_csv(\"stem_voc_test.csv\")\n",
    "\n",
    "# train_text, test_text = load_stem_voc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c089c98",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-10T02:09:53.146Z"
    },
    "id": "9c089c98",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### label mapper\n",
    "####################################\n",
    "labels = sorted(train_label.unique())\n",
    "label_mapper = dict(zip(labels, range(len(labels))))\n",
    "train_label = train_label.map(label_mapper)\n",
    "test_label = test_label.map(label_mapper)\n",
    "y_train = train_label\n",
    "y_test = test_label\n",
    "\n",
    "print(train_text.shape)\n",
    "print(test_text.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a125b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-10T02:09:53.147Z"
    },
    "id": "859a125b"
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### hyper params \n",
    "####################################\n",
    "filters = '\"#$%&()*+,-/:;<=>@[\\\\]^_`{|}~\\t\\n0123465789!.?\\''\n",
    "MAX_NB_WORDS_ratio = 0.95\n",
    "MAX_DOC_LEN_ratio = 0.99\n",
    "MAX_NB_WORDS = eda_MAX_NB_WORDS(train_text, ratio=MAX_NB_WORDS_ratio, char_level=False, filters=filters)\n",
    "MAX_DOC_LEN = eda_MAX_DOC_LEN(train_text, ratio=MAX_DOC_LEN_ratio, char_level=False, filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef858a91",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-10T02:09:53.149Z"
    },
    "id": "ef858a91"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, Dropout, Activation, Input, Flatten, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686b4f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41be8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd1183b7",
   "metadata": {
    "id": "fd1183b7"
   },
   "source": [
    "## extra one-hot features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f5083",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-10T02:09:53.239Z"
    },
    "id": "b51f5083",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one_hot_X_train, one_hot_X_test, one_hot_word_to_idx, one_hot_count_vect = count_vectorizer(\n",
    "#     train['Subject']+\" \" + train['Organization'], test['Subject']+\" \" + test['Organization'], stop_words=True, binary=False, min_df=3, max_df=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d56d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T01:43:16.717443Z",
     "start_time": "2021-12-10T01:43:16.706441Z"
    },
    "id": "269d56d2"
   },
   "source": [
    "## extra keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50842dc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-10T02:09:53.275Z"
    },
    "id": "a50842dc"
   },
   "outputs": [],
   "source": [
    "# label_docs = train.groupby('label')['text'].apply(lambda x: \" \".join(x)) # 要去除标点符号\n",
    "# dtm, _, label_word_to_idx, _ = count_vectorizer(label_docs, [''], stop_words=True, min_df=1, binary=True)\n",
    "# label_idx_to_word = dict([val, key] for key, val in label_word_to_idx.items())\n",
    "# keywords_threshold = 1\n",
    "# keywords_idx = np.where(dtm.sum(axis=0)<=keywords_threshold)[0]\n",
    "# print(\" keywords_idx shape: \")\n",
    "# voc = [label_idx_to_word[idx] for idx in keywords_idx]\n",
    "\n",
    "# keywords_X_train, keywords_X_test, keywords_word_to_idx, keywords_count_vect = count_vectorizer(\n",
    "#     train['text'], test['text'], voc=voc, stop_words=True, min_df=1, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a938ba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-10T02:09:53.312Z"
    },
    "id": "b9a938ba"
   },
   "outputs": [],
   "source": [
    "_X_train = np.hstack([X_train])\n",
    "_X_test = np.hstack([X_test])\n",
    "# _X_train = np.hstack([X_train, one_hot_X_train, keywords_X_train])\n",
    "# _X_test = np.hstack([X_test, one_hot_X_test, keywords_X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc232d5",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8350e74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T02:40:11.072229Z",
     "start_time": "2021-12-10T02:40:11.065229Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "from bert_utils.training_utils import extract_contextual_embedding, train_multi_label_model, model_eval\n",
    "from bert_utils import glovar \n",
    "from bert_utils.data_loader import data_loading, BERT_data_loader, preprocessing_for_emo_mix_balance\n",
    "from bert_utils.maml_training_utils import MAML_train, history_vis \n",
    "from bert_utils.maml_dataloader import MAML_Data_loader, MAML_train_val_split\n",
    "from torchinfo import summary\n",
    "from bert_utils.model2 import clf, lstm_cnn_o2\n",
    "from model import lstm_cnn_o1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "621349ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T02:40:15.647445Z",
     "start_time": "2021-12-10T02:40:13.586174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "BertModel                                          --\n",
       "├─BertEmbeddings: 1-1                              --\n",
       "│    └─Embedding: 2-1                              23,440,896\n",
       "│    └─Embedding: 2-2                              393,216\n",
       "│    └─Embedding: 2-3                              1,536\n",
       "│    └─LayerNorm: 2-4                              1,536\n",
       "│    └─Dropout: 2-5                                --\n",
       "├─BertEncoder: 1-2                                 --\n",
       "│    └─ModuleList: 2-6                             --\n",
       "│    │    └─BertLayer: 3-1                         7,087,872\n",
       "│    │    └─BertLayer: 3-2                         7,087,872\n",
       "│    │    └─BertLayer: 3-3                         7,087,872\n",
       "│    │    └─BertLayer: 3-4                         7,087,872\n",
       "│    │    └─BertLayer: 3-5                         7,087,872\n",
       "│    │    └─BertLayer: 3-6                         7,087,872\n",
       "│    │    └─BertLayer: 3-7                         7,087,872\n",
       "│    │    └─BertLayer: 3-8                         7,087,872\n",
       "│    │    └─BertLayer: 3-9                         7,087,872\n",
       "│    │    └─BertLayer: 3-10                        7,087,872\n",
       "│    │    └─BertLayer: 3-11                        7,087,872\n",
       "│    │    └─BertLayer: 3-12                        7,087,872\n",
       "├─BertPooler: 1-3                                  --\n",
       "│    └─Linear: 2-7                                 590,592\n",
       "│    └─Tanh: 2-8                                   --\n",
       "===========================================================================\n",
       "Total params: 109,482,240\n",
       "Trainable params: 109,482,240\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_attentions = True, output_hidden_states = True)\n",
    "\n",
    "# global device\n",
    "device = glovar.device_type\n",
    "bert_model = bert_model.to(device)\n",
    "\n",
    "print(next(bert_model.parameters()).device)  # 输出：cpu\n",
    "summary(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b14157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAML = False\n",
    "embed_dim = 100\n",
    "max_len = MAX_DOC_LEN\n",
    "hidden_units = 10\n",
    "num_filters = 10\n",
    "kernel_sizes = [1,2,3]\n",
    "label_size = 20\n",
    "model_path = 'bert_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bce6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_ids, sentences_encoding = extract_contextual_embedding(sentences, tokenizer, bert_model, max_len = max_len)\n",
    "# np.save('sentences_encoding_u1_all_kiera.npy', sentences_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6eb114c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T02:40:50.115095Z",
     "start_time": "2021-12-10T02:40:50.102096Z"
    }
   },
   "outputs": [],
   "source": [
    "if MAML is True:\n",
    "    model = lstm_cnn_o1(embed_dim, max_len, hidden_units,\n",
    "                        num_filters, kernel_sizes, label_size)\n",
    "elif \"cnn\" in model_path:\n",
    "    model = lstm_cnn_o2(embed_dim, max_len, hidden_units,\n",
    "                        num_filters, kernel_sizes, label_size)\n",
    "else:\n",
    "    model = clf(embed_dim, max_len, hidden_units, label_size)\n",
    "\n",
    "# model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b87b973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T02:40:51.946984Z",
     "start_time": "2021-12-10T02:40:51.941980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "# print(summary(model,(batch_size, max_len, embed_dim), device=device)) # 为什么这句话会默认放到 gpu 上去\n",
    "print(next(model.parameters()).device)  # 输出：cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd06c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = to_categorical(y_train)\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "patience = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f1f862a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T02:41:35.524180Z",
     "start_time": "2021-12-10T02:41:35.498181Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences_encoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_1384/756992256.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msentences_encoding\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m Train_pos_set, Train_neg_set, Val_pos_set, Val_neg_set = MAML_train_val_split(\n\u001b[0;32m      3\u001b[0m     df, sources)\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# get data loaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_loaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentences_encoding' is not defined"
     ]
    }
   ],
   "source": [
    "# Data Loader\n",
    "dataloader, validation_dataloader = BERT_data_loader(\n",
    "    sentences_encoding, input_ids, one_hot_labels, batch_size, random_state=12345, test_size=0.1, testing=testing)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "total_steps = len(dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(total_steps*0.1), num_training_steps=total_steps)\n",
    "model, training_stats = train_multi_label_model(model, label_size, label_cols, dataloader, validation_dataloader,\n",
    "                                                optimizer=optimizer, scheduler=scheduler, epochs=epochs, patience=patience, model_path=model_path)\n",
    "\n",
    "pd.set_option('precision', 2)\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "# df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "df_stats.to_csv(model_path[0:-2]+'csv')\n",
    "\n",
    "print('num of samples: ', sentences_encoding.shape[0])\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "plt.legend()\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(list(range(1, epochs+1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c76c8c1",
   "metadata": {
    "id": "4c76c8c1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0a439",
   "metadata": {
    "id": "f6b0a439"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "def generate_classification_report(test_file):\n",
    "    if 'txt' in test_file:\n",
    "        df = pd.read_csv(os.path.join('data', 'test', test_file), sep='|')\n",
    "    else:\n",
    "        df = pd.read_excel(os.path.join('data', 'test', test_file))\n",
    "\n",
    "    df = df.dropna()\n",
    "    sentences = df.sentence.values\n",
    "    labels = df.label.values\n",
    "\n",
    "    # get embedding\n",
    "    _, _, x = extract_contextual_embedding(sentences, tokenizer, bert_model, max_len = max_len)\n",
    "    x = torch.tensor(x, dtype=training_dtype).to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = maml(x).view(-1).detach().cpu().numpy()\n",
    "\n",
    "    print(classification_report(labels, preds>=0.5))\n",
    "    return labels, preds\n",
    "\n",
    "test_file = 'surprise_dt_test_v9_all_kiera.xlsx'\n",
    "l, p = generate_classification_report(test_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NN_based_models_Deep_tfidf+onehot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "190.458px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
