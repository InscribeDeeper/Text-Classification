{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "992acfb5",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Grid-Search\" data-toc-modified-id=\"Grid-Search-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Grid Search</a></span></li><li><span><a href=\"#Best-params-result\" data-toc-modified-id=\"Best-params-result-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Best params result</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182eba31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:35:24.824602Z",
     "start_time": "2021-12-09T06:35:24.812601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cdb4c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:35:31.643713Z",
     "start_time": "2021-12-09T06:35:26.595602Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from clustering_utils import *\n",
    "from eda_utils import *\n",
    "from myutils_V6 import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8032170b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:35:33.174780Z",
     "start_time": "2021-12-09T06:35:31.645714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "may use cols: \n",
      " ['global_index', 'doc_path', 'label', 'reply', 'reference_one', 'reference_two', 'tag_reply', 'tag_reference_one', 'tag_reference_two', 'Subject', 'From', 'Lines', 'Organization', 'contained_emails', 'long_string', 'text', 'error_message']\n"
     ]
    }
   ],
   "source": [
    "train, test = load_data()\n",
    "# train, upsampling_info = upsampling_train(train)\n",
    "\n",
    "train_text, train_label = train_augmentation(train, select_comb=None)\n",
    "test_text, test_label = test['text'], test['label']\n",
    "\n",
    "# test_text = test_text.apply(lambda x: normal_string(x))\n",
    "# train_text = train_text.apply(lambda x: normal_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba90b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:36:35.403865Z",
     "start_time": "2021-12-09T06:36:35.395865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11083,)\n",
      "(7761,)\n",
      "(11083,)\n",
      "(7761,)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "### label mapper\n",
    "####################################\n",
    "labels = sorted(train_label.unique())\n",
    "label_mapper = dict(zip(labels, range(len(labels))))\n",
    "train_label = train_label.map(label_mapper)\n",
    "test_label = test_label.map(label_mapper)\n",
    "y_train = train_label\n",
    "y_test = test_label\n",
    "\n",
    "print(train_text.shape)\n",
    "print(test_text.shape)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2824004b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T04:06:45.619843Z",
     "start_time": "2021-12-09T04:06:45.615842Z"
    }
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b804b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13434f23",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:40.077Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = \"f1_macro\"\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])\n",
    "parameters = {'tfidf__min_df': [1, 3, 5], 'tfidf__stop_words': [None, 'english'], 'tfidf__use_idf': [True, False], 'tfidf__binary': [True, False],\n",
    "              'clf__alpha': [0.6, 0.8, 1]}\n",
    "gs_clf = GridSearchCV(text_clf, scoring=metric, param_grid=parameters, cv=4)\n",
    "gs_clf = gs_clf.fit(train_text, y_train)\n",
    "\n",
    "for param_name in gs_clf.best_params_:\n",
    "    print(\"{0}:\\t{1}\".format(param_name, gs_clf.best_params_[param_name]))\n",
    "\n",
    "print(\"best f1 score: {:.3f}\".format(gs_clf.best_score_))\n",
    "cv_results = pd.DataFrame(gs_clf.cv_results_)\n",
    "cv_results.to_excel(f\"NB_cv_result_{nb_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc14795",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:40.084Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = \"f1_macro\"\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])\n",
    "parameters = {'tfidf__min_df': [1, 3, 5], 'tfidf__stop_words': [None, 'english'], 'tfidf__use_idf': [True, False], 'tfidf__binary': [True, False],\n",
    "             'clf__penalty':['l2'], 'clf__C':[1,2,3]}\n",
    "gs_clf = GridSearchCV(text_clf, scoring=metric, param_grid=parameters, cv=4)\n",
    "gs_clf = gs_clf.fit(train_text, y_train)\n",
    "\n",
    "for param_name in gs_clf.best_params_:\n",
    "    print(\"{0}:\\t{1}\".format(param_name, gs_clf.best_params_[param_name]))\n",
    "\n",
    "print(\"best f1 score: {:.3f}\".format(gs_clf.best_score_))\n",
    "cv_results = pd.DataFrame(gs_clf.cv_results_)\n",
    "cv_results.to_excel(f\"SVC_cv_result_{nb_name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387aad7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ebd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b926dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39edd12d",
   "metadata": {},
   "source": [
    "# Best params result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96715dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:36:57.396923Z",
     "start_time": "2021-12-09T06:36:47.197476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of words: 24961\n",
      "num of words: 38157\n",
      "X_train.shape (11083, 38157)\n",
      "X_test.shape (7761, 38157)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, word_to_idx, tfidf_vect = tfidf_vectorizer(train_text, test_text, min_df=3, max_df=0.001)\n",
    "X_train, X_test, word_to_idx, tfidf_vect = count_vectorizer(train_text, test_text, min_df=3, max_df=0.95)\n",
    "# tfidf_vectorizer(train_text, test_text, min_df=2, max_df=100)\n",
    "# X_train, transform_mapper = dimension_reduction(X_train, out_dim=500)\n",
    "# X_test = transform_mapper.transform(X_test)\n",
    "\n",
    "print('X_train.shape', X_train.shape)\n",
    "print('X_test.shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909d5e9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:40.208Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(penalty=\"l2\", multi_class='ovr', C=1.0, dual=True, max_iter=5000)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_true = y_test, y_pred=pred, target_names=labels))\n",
    "\n",
    "##########################################\n",
    "## CV shows the stable result\n",
    "##########################################\n",
    "cv_metrics = [\"precision_macro\",\"accuracy\", \"f1_macro\"]\n",
    "cv = cross_validate(clf, X_train, y_train,scoring=cv_metrics, cv=4, return_train_score=True)\n",
    "cv = pd.DataFrame(cv)\n",
    "f1 = cv['test_f1_macro'].mean()\n",
    "print(\"cv average f1 macro: \", f1)\n",
    "\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc2302",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:40.210Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_true = y_test, y_pred=pred, target_names=labels))\n",
    "\n",
    "\n",
    "##########################################\n",
    "## CV shows the stable result\n",
    "##########################################\n",
    "cv_metrics = [\"precision_macro\",\"accuracy\", \"f1_macro\"]\n",
    "cv = cross_validate(clf, X_train, y_train,scoring=cv_metrics, cv=4, return_train_score=True)\n",
    "cv = pd.DataFrame(cv)\n",
    "f1 = cv['test_f1_macro'].mean()\n",
    "print(\"cv average f1 macro: \", f1)\n",
    "\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90eac02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da27221a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T06:38:48.864427Z",
     "start_time": "2021-12-09T06:37:32.571080Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\py810\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74       319\n",
      "           1       0.67      0.75      0.71       389\n",
      "           2       0.73      0.68      0.70       394\n",
      "           3       0.63      0.70      0.66       392\n",
      "           4       0.76      0.79      0.78       385\n",
      "           5       0.83      0.74      0.78       395\n",
      "           6       0.77      0.86      0.81       390\n",
      "           7       0.86      0.86      0.86       395\n",
      "           8       0.93      0.90      0.92       398\n",
      "           9       0.65      0.91      0.75       397\n",
      "          10       0.99      0.70      0.82       827\n",
      "          11       0.93      0.87      0.90       396\n",
      "          12       0.66      0.68      0.67       393\n",
      "          13       0.64      0.91      0.75       198\n",
      "          14       0.92      0.89      0.90       394\n",
      "          15       0.83      0.91      0.87       398\n",
      "          16       0.71      0.84      0.77       364\n",
      "          17       0.97      0.82      0.89       376\n",
      "          18       0.71      0.53      0.61       310\n",
      "          19       0.63      0.61      0.62       251\n",
      "\n",
      "    accuracy                           0.78      7761\n",
      "   macro avg       0.78      0.78      0.78      7761\n",
      "weighted avg       0.80      0.78      0.78      7761\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\py810\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\py810\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Administrator\\Anaconda3\\envs\\py810\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv average f1 macro:  0.8367343005712865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\envs\\py810\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>train_precision_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>train_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.873764</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>0.813455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.808012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.634575</td>\n",
       "      <td>0.014003</td>\n",
       "      <td>0.867820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861632</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.894090</td>\n",
       "      <td>0.012999</td>\n",
       "      <td>0.871465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862724</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.695365</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.827752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.825632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820079</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_precision_macro  train_precision_macro  \\\n",
       "0  14.873764    0.013001              0.813455                    1.0   \n",
       "1  16.634575    0.014003              0.867820                    1.0   \n",
       "2  13.894090    0.012999              0.871465                    1.0   \n",
       "3  15.695365    0.012000              0.827752                    1.0   \n",
       "\n",
       "   test_accuracy  train_accuracy  test_f1_macro  train_f1_macro  \n",
       "0       0.808012             1.0       0.802502             1.0  \n",
       "1       0.862505             1.0       0.861632             1.0  \n",
       "2       0.869722             1.0       0.862724             1.0  \n",
       "3       0.825632             1.0       0.820079             1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(metrics.classification_report(y_true = y_test, y_pred=pred))\n",
    "\n",
    "\n",
    "##########################################\n",
    "## CV shows the stable result\n",
    "##########################################\n",
    "cv_metrics = [\"precision_macro\",\"accuracy\", \"f1_macro\"]\n",
    "cv = cross_validate(clf, X_train, y_train,scoring=cv_metrics, cv=4, return_train_score=True)\n",
    "cv = pd.DataFrame(cv)\n",
    "f1 = cv['test_f1_macro'].mean()\n",
    "print(\"cv average f1 macro: \", f1)\n",
    "\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b76de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b10f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0c6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75667688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004c3b6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:40.241Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "p = (clf.predict_proba(test_dtm))[:, 1] \n",
    "p_binary = clf.predict(test_dtm)\n",
    "\n",
    "p_label = 2\n",
    "fpr, tpr, thresholds = roc_curve(test_y, p, pos_label=p_label)\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "pre, rec, thresholds = precision_recall_curve(test_y, p, pos_label=p_label)\n",
    "\n",
    "# calculate auc\n",
    "prc_score = auc(rec, pre)\n",
    "\n",
    "if show_plots:\n",
    "\n",
    "    print(classification_report(test_y, p_binary))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('AUC')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(rec, pre, color='darkorange', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('PRC')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print(\"AUC: {:.2%}, PRC: {:.2%}\".format(auc_score, prc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff534d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9075978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53356a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a419ac1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:40.326Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176607d6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-09T05:53:40.327Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, roc_curve, auc, precision_recall_curve\n",
    "# mapping from integer feature name to original token string\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Feature reduction with Kbest features based on chi2 score\n",
    "ch2 = SelectKBest(chi2, k=50000)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)\n",
    "if feature_names:\n",
    "    # keep selected feature names\n",
    "    feature_names = [feature_names[i] for i in ch2.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48100b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d59675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e2da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd70a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ee357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T03:48:57.019131Z",
     "start_time": "2021-12-09T03:48:57.017130Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac15efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
