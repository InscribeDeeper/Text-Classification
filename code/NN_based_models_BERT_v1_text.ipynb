{"cells":[{"cell_type":"markdown","id":"d89dfe26","metadata":{"id":"d89dfe26","toc":true},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Colab\" data-toc-modified-id=\"Colab-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Colab</a></span></li><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loading</a></span><ul class=\"toc-item\"><li><span><a href=\"#extra-one-hot-features\" data-toc-modified-id=\"extra-one-hot-features-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>extra one-hot features</a></span></li><li><span><a href=\"#extra-keywords\" data-toc-modified-id=\"extra-keywords-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>extra keywords</a></span></li></ul></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>BERT</a></span></li></ul></div>"]},{"cell_type":"markdown","id":"05c43715","metadata":{"id":"05c43715"},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#TextCNN\" data-toc-modified-id=\"TextCNN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TextCNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#notes:\" data-toc-modified-id=\"notes:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>notes:</a></span></li></ul></li><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>LSTM</a></span></li></ul></div>"]},{"cell_type":"markdown","id":"3e4f5360","metadata":{"id":"3e4f5360"},"source":["# Colab"]},{"cell_type":"code","execution_count":27,"id":"85be328c","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:09:53.148780Z","start_time":"2021-12-10T02:09:53.144780Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"85be328c","outputId":"85356c1c-4b3e-4b73-e586-4769af1de214","scrolled":true,"executionInfo":{"status":"ok","timestamp":1639126641450,"user_tz":300,"elapsed":8947,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.4)\n","Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.16)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.0.0)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.4)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: pandas==1.3.0 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (1.21.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.0) (1.15.0)\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/MyDrive/Text-Classification/code\")\n","!pip install pyLDAvis\n","!pip install gensim\n","!pip install pandas==1.3.0"]},{"cell_type":"markdown","id":"e2c39454","metadata":{"id":"e2c39454"},"source":["# Import "]},{"cell_type":"code","execution_count":28,"id":"7ea8c845","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:09:58.418780Z","start_time":"2021-12-10T02:09:53.150782Z"},"id":"7ea8c845","executionInfo":{"status":"ok","timestamp":1639126641451,"user_tz":300,"elapsed":15,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["from classification_utils import *\n","from clustering_utils import *\n","from eda_utils import *\n","from nn_utils_keras import *\n","from feature_engineering_utils import *\n","from data_utils import *"]},{"cell_type":"markdown","id":"83f27bb1","metadata":{"id":"83f27bb1"},"source":["# Loading"]},{"cell_type":"code","execution_count":29,"id":"f88921e6","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:11:34.258Z"},"id":"f88921e6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639126643711,"user_tz":300,"elapsed":2275,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"77783e1e-0a51-4443-d2e2-130d76b711e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","may use cols: \n"," ['global_index', 'doc_path', 'label', 'reply', 'reference_one', 'reference_two', 'tag_reply', 'tag_reference_one', 'tag_reference_two', 'Subject', 'From', 'Lines', 'Organization', 'contained_emails', 'long_string', 'text', 'error_message']\n","combination 1 train:  ['reply', 'reference_one', 'reference_two']\n"]}],"source":["train, test = load_data(only_stem_voc=False, sample50=False)\n","# train, upsampling_info = upsampling_train(train)\n","\n","train_text, train_label = train_augmentation(train, select_comb=[['text'], ['reply', 'reference_one', 'reference_two']])\n","# train_text, train_label = train['text'], train['label']\n","# test_text, test_label = test['text'], test['label']\n","test_text, test_label = test[['reply', 'reference_one', 'reference_two']].apply(lambda x: \" \".join(x), axis=1), test['label']\n","\n","\n","# test_text = test_text.apply(lambda x: extract_stem_voc(x))\n","# train_text = train_text.apply(lambda x: extract_stem_voc(x))\n","# train_text.to_csv(\"stem_voc_train.csv\")\n","# test_text.to_csv(\"stem_voc_test.csv\")\n","\n","# train_text, test_text = load_stem_voc()"]},{"cell_type":"code","execution_count":30,"id":"9c089c98","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.146Z"},"id":"9c089c98","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639126643711,"user_tz":300,"elapsed":16,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"6d9e5176-3943-4c76-95a0-583a8b615cde"},"outputs":[{"output_type":"stream","name":"stdout","text":["(11083,)\n","(7761,)\n","(11083,)\n","(7761,)\n","['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"]}],"source":["####################################\n","### label mapper\n","####################################\n","labels = sorted(train_label.unique())\n","label_mapper = dict(zip(labels, range(len(labels))))\n","train_label = train_label.map(label_mapper)\n","test_label = test_label.map(label_mapper)\n","y_train = train_label\n","y_test = test_label\n","\n","print(train_text.shape)\n","print(test_text.shape)\n","print(train_label.shape)\n","print(test_label.shape)\n","print(labels)"]},{"cell_type":"code","execution_count":31,"id":"859a125b","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.147Z"},"id":"859a125b","executionInfo":{"status":"ok","timestamp":1639126643712,"user_tz":300,"elapsed":15,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["####################################\n","### hyper params \n","####################################\n","# filters = '\"#$%&()*+,-/:;<=>@[\\\\]^_`{|}~\\t\\n0123465789!.?\\''\n","# MAX_NB_WORDS_ratio = 0.95\n","# MAX_DOC_LEN_ratio = 0.99\n","# MAX_NB_WORDS = eda_MAX_NB_WORDS(train_text, ratio=MAX_NB_WORDS_ratio, char_level=False, filters=filters)\n","# MAX_DOC_LEN = eda_MAX_DOC_LEN(train_text, ratio=MAX_DOC_LEN_ratio, char_level=False, filters=filters)"]},{"cell_type":"code","source":["# X_train, X_test, word_to_idx, tfidf_vect = tfidf_vectorizer(train_text, test_text, stop_words=True, binary=True, min_df=5)\n","# X_train, transform_mapper = dimension_reduction(X_train, out_dim=1000) # not allow negative \n","# X_test = transform_mapper.transform(X_test)"],"metadata":{"id":"JnQpGP-FR6x9","executionInfo":{"status":"ok","timestamp":1639126643712,"user_tz":300,"elapsed":14,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"id":"JnQpGP-FR6x9","execution_count":32,"outputs":[]},{"cell_type":"markdown","id":"fd1183b7","metadata":{"id":"fd1183b7"},"source":["## extra one-hot features"]},{"cell_type":"code","execution_count":33,"id":"b51f5083","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.239Z"},"id":"b51f5083","scrolled":true,"executionInfo":{"status":"ok","timestamp":1639126643713,"user_tz":300,"elapsed":15,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["# one_hot_X_train, one_hot_X_test, one_hot_word_to_idx, one_hot_count_vect = count_vectorizer(\n","#     train['Subject']+\" \" + train['Organization'], test['Subject']+\" \" + test['Organization'], stop_words=True, binary=False, min_df=3, max_df=0.001)"]},{"cell_type":"markdown","id":"269d56d2","metadata":{"ExecuteTime":{"end_time":"2021-12-10T01:43:16.717443Z","start_time":"2021-12-10T01:43:16.706441Z"},"id":"269d56d2"},"source":["## extra keywords"]},{"cell_type":"code","execution_count":34,"id":"a50842dc","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.275Z"},"id":"a50842dc","executionInfo":{"status":"ok","timestamp":1639126643713,"user_tz":300,"elapsed":15,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["# label_docs = train.groupby('label')['text'].apply(lambda x: \" \".join(x)) # 要去除标点符号\n","# dtm, _, label_word_to_idx, _ = count_vectorizer(label_docs, [''], stop_words=True, min_df=1, binary=True)\n","# label_idx_to_word = dict([val, key] for key, val in label_word_to_idx.items())\n","# keywords_threshold = 1\n","# keywords_idx = np.where(dtm.sum(axis=0)<=keywords_threshold)[0]\n","# print(\" keywords_idx shape: \")\n","# voc = [label_idx_to_word[idx] for idx in keywords_idx]\n","\n","# keywords_X_train, keywords_X_test, keywords_word_to_idx, keywords_count_vect = count_vectorizer(\n","#     train['text'], test['text'], voc=voc, stop_words=True, min_df=1, binary=True)"]},{"cell_type":"code","execution_count":35,"id":"b9a938ba","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.312Z"},"id":"b9a938ba","executionInfo":{"status":"ok","timestamp":1639126643714,"user_tz":300,"elapsed":16,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["# _X_train = np.hstack([X_train])\n","# _X_test = np.hstack([X_test])\n","# _X_train = np.hstack([X_train, one_hot_X_train, keywords_X_train])\n","# _X_test = np.hstack([X_test, one_hot_X_test, keywords_X_test])"]},{"cell_type":"markdown","id":"2dc232d5","metadata":{"id":"2dc232d5"},"source":["# BERT"]},{"cell_type":"code","execution_count":36,"id":"d8350e74","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:40:11.072229Z","start_time":"2021-12-10T02:40:11.065229Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"d8350e74","executionInfo":{"status":"ok","timestamp":1639126649171,"user_tz":300,"elapsed":5273,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"bbe44a38-696c-4a33-d672-f16040c815f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.5.4)\n"]}],"source":["!pip install transformers\n","!pip install torchinfo\n","import torch\n","import torch.nn.functional as F\n","\n","from torchinfo import summary\n","from transformers import BertTokenizer, BertModel, AdamW, BertConfig, get_linear_schedule_with_warmup\n","\n","from bert_utils.training_utils import extract_contextual_embedding, train_multi_label_model, model_eval\n","from bert_utils.data_loader import  data_loader_BERT\n","from bert_utils import glovar \n","from bert_utils.model import *"]},{"cell_type":"code","source":["train_one_hot_labels = F.one_hot(torch.tensor(y_train.values))\n","test_one_hot_labels = F.one_hot(torch.tensor(test_label.values))"],"metadata":{"id":"aRfQroUrnRGp","executionInfo":{"status":"ok","timestamp":1639126649172,"user_tz":300,"elapsed":12,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"id":"aRfQroUrnRGp","execution_count":37,"outputs":[]},{"cell_type":"code","execution_count":38,"id":"621349ed","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:40:15.647445Z","start_time":"2021-12-10T02:40:13.586174Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"621349ed","executionInfo":{"status":"ok","timestamp":1639126653911,"user_tz":300,"elapsed":4750,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"4a8e7fcd-75be-4ad1-acfd-90781f9672b2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["cuda:0\n"]},{"output_type":"execute_result","data":{"text/plain":["===========================================================================\n","Layer (type:depth-idx)                             Param #\n","===========================================================================\n","BertModel                                          --\n","├─BertEmbeddings: 1-1                              --\n","│    └─Embedding: 2-1                              23,440,896\n","│    └─Embedding: 2-2                              393,216\n","│    └─Embedding: 2-3                              1,536\n","│    └─LayerNorm: 2-4                              1,536\n","│    └─Dropout: 2-5                                --\n","├─BertEncoder: 1-2                                 --\n","│    └─ModuleList: 2-6                             --\n","│    │    └─BertLayer: 3-1                         7,087,872\n","│    │    └─BertLayer: 3-2                         7,087,872\n","│    │    └─BertLayer: 3-3                         7,087,872\n","│    │    └─BertLayer: 3-4                         7,087,872\n","│    │    └─BertLayer: 3-5                         7,087,872\n","│    │    └─BertLayer: 3-6                         7,087,872\n","│    │    └─BertLayer: 3-7                         7,087,872\n","│    │    └─BertLayer: 3-8                         7,087,872\n","│    │    └─BertLayer: 3-9                         7,087,872\n","│    │    └─BertLayer: 3-10                        7,087,872\n","│    │    └─BertLayer: 3-11                        7,087,872\n","│    │    └─BertLayer: 3-12                        7,087,872\n","├─BertPooler: 1-3                                  --\n","│    └─Linear: 2-7                                 590,592\n","│    └─Tanh: 2-8                                   --\n","===========================================================================\n","Total params: 109,482,240\n","Trainable params: 109,482,240\n","Non-trainable params: 0\n","==========================================================================="]},"metadata":{},"execution_count":38}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_attentions = True, output_hidden_states = True)\n","# global device\n","device = glovar.device_type\n","bert_model = bert_model.to(device)\n","print(next(bert_model.parameters()).device)  # 输出：cpu\n","summary(bert_model)"]},{"cell_type":"code","execution_count":39,"id":"d9f6a91a","metadata":{"id":"d9f6a91a","executionInfo":{"status":"ok","timestamp":1639126653912,"user_tz":300,"elapsed":27,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["load_embed= False\n","\n","learning_rate = 0.0001\n","epochs = 40\n","patience = 10\n","MAX_DOC_LEN = 200\n","batch_size=32\n","\n","\n","max_len = min(512, MAX_DOC_LEN)\n","label_size = 20\n","label_cols = labels\n","embed_dim = 768\n","hidden_units = 64\n","num_filters = 30\n","kernel_sizes = [1,2,3]"]},{"cell_type":"code","source":["if load_embed is True:\n","    train_sentences_encoding = np.load('train_sentences_encoding.npy')# , mmap_mode='r')\n","    train_input_ids = np.load('train_input_ids.npy')#, mmap_mode='r')\n","    train_sentences_encoding = torch.tensor(train_sentences_encoding)\n","    train_input_ids = torch.tensor(train_input_ids)\n","else:\n","    train_input_ids, train_sentences_encoding = extract_contextual_embedding(train_text, tokenizer, bert_model, max_len = max_len, low_RAM_inner_batch=True)\n","    # train_input_ids, train_sentences_encoding = extract_contextual_embedding(train_text.iloc[1:3], tokenizer, bert_model, max_len = max_len, low_RAM_inner_batch=False) test\n","    np.save('train_sentences_encoding.npy', train_sentences_encoding)\n","    np.save('train_input_ids.npy', train_input_ids)\n","\n","\n","dataloader, validation_dataloader = data_loader_BERT(train_sentences_encoding, train_input_ids, train_one_hot_labels, batch_size, random_state=1234, test_size=0.1)\n","del train_sentences_encoding, train_input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJLMUVgVYema","outputId":"2468493b-ea36-4e82-a694-79aa458c39cb"},"id":"OJLMUVgVYema","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","execution_count":null,"id":"6eb114c3","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:40:50.115095Z","start_time":"2021-12-10T02:40:50.102096Z"},"id":"6eb114c3"},"outputs":[],"source":["model_path = 'bert_clf'\n","label_size = len(labels)\n","# model = lstm_cnn_o1(embed_dim, max_len, hidden_units, num_filters, kernel_sizes, label_size)\n","# model = lstm_cnn_o2(embed_dim, max_len, hidden_units, num_filters, kernel_sizes, label_size)\n","# model = clf(embed_dim, max_len, hidden_units, label_size)\n","model = clf_naive(embed_dim, max_len, hidden_units, label_size, dropout_rate=0.2)\n","model.to(device)"]},{"cell_type":"code","source":["[torch.cuda.empty_cache() for _ in range(10) ]\n","print(torch.cuda.memory_summary())"],"metadata":{"id":"y75AD5TEun3D"},"id":"y75AD5TEun3D","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"0f1f862a","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:41:35.524180Z","start_time":"2021-12-10T02:41:35.498181Z"},"id":"0f1f862a"},"outputs":[],"source":["model = clf_naive(embed_dim, max_len, hidden_units, label_size, dropout_rate=0.2)\n","model.to(device)\n","\n","# Data Loader\n","\n","optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n","total_steps = len(dataloader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * 0.1), num_training_steps=total_steps)\n","model, training_stats, pred_labels, true_labels = train_multi_label_model(model, label_size, label_cols, dataloader, validation_dataloader, optimizer=optimizer, scheduler=scheduler, epochs=epochs, patience=patience, model_path=model_path)\n","\n","\n","pd.set_option('precision', 2)\n","df_stats = pd.DataFrame(data=training_stats)\n","df_stats = df_stats.set_index('epoch')\n","df_stats.to_csv(model_path[0:-2] + 'csv')\n","\n","import seaborn as sns\n","sns.set(style='darkgrid')\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12, 6)\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","plt.legend()\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.xticks(list(range(1, epochs + 1)))\n","plt.show()"]},{"cell_type":"code","source":["# model.load_state_dict(torch.load(model_path))"],"metadata":{"id":"flba59bywKcr"},"id":"flba59bywKcr","execution_count":null,"outputs":[]},{"cell_type":"code","source":["if load_embed is True:\n","    test_sentences_encoding = np.load('test_sentences_encoding.npy')#, mmap_mode='r')\n","    test_input_ids = np.load('test_input_ids.npy') # , mmap_mode='r')\n","    test_sentences_encoding = torch.tensor(test_sentences_encoding)\n","    test_input_ids = torch.tensor(test_input_ids)\n","else:\n","    test_input_ids, test_sentences_encoding = extract_contextual_embedding(test_text, tokenizer, bert_model, max_len = max_len, low_RAM_inner_batch=True)\n","    np.save('test_sentences_encoding.npy', test_sentences_encoding)\n","    np.save('test_input_ids.npy', test_input_ids)\n","\n","\n","test_dataloader, _ = data_loader_BERT(test_sentences_encoding,test_input_ids, test_one_hot_labels, testing=True)\n","del test_sentences_encoding, test_input_ids\n","\n","tokenized_texts, pred_labels, true_labels, avg_val_loss, auc_score, precison, recall, acc, f1 = model_eval(model, test_dataloader,  labels , class_weight=None)\n","classification_report = evaluation_report(np.argmax(true_labels, axis=1),  np.argmax(pred_labels, axis=1), labels=labels)\n","roc_auc(y_test, pred_labels)"],"metadata":{"id":"z7axjlu1jF7u"},"id":"z7axjlu1jF7u","execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"WWPQPVQGiuwz"},"id":"WWPQPVQGiuwz","execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CsHy7qC4iWK6"},"id":"CsHy7qC4iWK6","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"NN_based_models_BERT_v1_text.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"190.458px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":5}