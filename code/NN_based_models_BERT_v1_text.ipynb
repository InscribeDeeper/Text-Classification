{"cells":[{"cell_type":"markdown","id":"d89dfe26","metadata":{"id":"d89dfe26","toc":true},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Colab\" data-toc-modified-id=\"Colab-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Colab</a></span></li><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Loading</a></span><ul class=\"toc-item\"><li><span><a href=\"#extra-one-hot-features\" data-toc-modified-id=\"extra-one-hot-features-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>extra one-hot features</a></span></li><li><span><a href=\"#extra-keywords\" data-toc-modified-id=\"extra-keywords-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>extra keywords</a></span></li></ul></li><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>BERT</a></span></li></ul></div>"]},{"cell_type":"markdown","id":"05c43715","metadata":{"id":"05c43715"},"source":["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n","<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#TextCNN\" data-toc-modified-id=\"TextCNN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TextCNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#notes:\" data-toc-modified-id=\"notes:-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>notes:</a></span></li></ul></li><li><span><a href=\"#LSTM\" data-toc-modified-id=\"LSTM-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>LSTM</a></span></li></ul></div>"]},{"cell_type":"markdown","id":"3e4f5360","metadata":{"id":"3e4f5360"},"source":["# Colab"]},{"cell_type":"code","execution_count":1,"id":"85be328c","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:09:53.148780Z","start_time":"2021-12-10T02:09:53.144780Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"85be328c","outputId":"1c96c060-6cfd-4e50-f5f7-6e1198984916","scrolled":true,"executionInfo":{"status":"ok","timestamp":1639130188954,"user_tz":300,"elapsed":8892,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n","Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.16)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.0.0)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.4)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: pandas==1.3.0 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2018.9)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (1.21.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.0) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.0) (1.15.0)\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/MyDrive/Text-Classification/code\")\n","!pip install pyLDAvis\n","!pip install gensim\n","!pip install pandas==1.3.0"]},{"cell_type":"markdown","id":"e2c39454","metadata":{"id":"e2c39454"},"source":["# Import "]},{"cell_type":"code","execution_count":2,"id":"7ea8c845","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:09:58.418780Z","start_time":"2021-12-10T02:09:53.150782Z"},"id":"7ea8c845","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639130191691,"user_tz":300,"elapsed":2745,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"83be161f-1b57-4b54-e6d1-8e5969679230"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n","  from collections import Iterable\n"]},{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]}],"source":["from classification_utils import *\n","from clustering_utils import *\n","from eda_utils import *\n","from nn_utils_keras import *\n","from feature_engineering_utils import *\n","from data_utils import *\n","import warnings \n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"83f27bb1","metadata":{"id":"83f27bb1"},"source":["# Loading"]},{"cell_type":"code","execution_count":3,"id":"f88921e6","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:11:34.258Z"},"id":"f88921e6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639130193759,"user_tz":300,"elapsed":2071,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"ce1331a4-537f-4cea-e80a-4fcd5a951f9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","may use cols: \n"," ['global_index', 'doc_path', 'label', 'reply', 'reference_one', 'reference_two', 'tag_reply', 'tag_reference_one', 'tag_reference_two', 'Subject', 'From', 'Lines', 'Organization', 'contained_emails', 'long_string', 'text', 'error_message']\n","combination 1 train:  ['reply', 'reference_one', 'reference_two']\n"]}],"source":["train, test = load_data(only_stem_voc=False, sample50=False)\n","# train, upsampling_info = upsampling_train(train)\n","\n","train_text, train_label = train_augmentation(train, select_comb=[['reply', 'reference_one', 'reference_two']])\n","# train_text, train_label = train_augmentation(train, select_comb=[['text'], ['reply', 'reference_one', 'reference_two']])\n","# train_text, train_label = train['text'], train['label']\n","# test_text, test_label = test['text'], test['label']\n","test_text, test_label = test[['reply', 'reference_one', 'reference_two']].apply(lambda x: \" \".join(x), axis=1), test['label']\n","\n","\n","# test_text = test_text.apply(lambda x: extract_stem_voc(x))\n","# train_text = train_text.apply(lambda x: extract_stem_voc(x))\n","# train_text.to_csv(\"stem_voc_train.csv\")\n","# test_text.to_csv(\"stem_voc_test.csv\")\n","\n","# train_text, test_text = load_stem_voc()"]},{"cell_type":"code","execution_count":4,"id":"9c089c98","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.146Z"},"id":"9c089c98","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639130193759,"user_tz":300,"elapsed":7,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"9a15254c-e744-4e5f-fd44-93e999743bf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["(11083,)\n","(7761,)\n","(11083,)\n","(7761,)\n","['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"]}],"source":["####################################\n","### label mapper\n","####################################\n","labels = sorted(train_label.unique())\n","label_mapper = dict(zip(labels, range(len(labels))))\n","train_label = train_label.map(label_mapper)\n","test_label = test_label.map(label_mapper)\n","y_train = train_label\n","y_test = test_label\n","\n","print(train_text.shape)\n","print(test_text.shape)\n","print(train_label.shape)\n","print(test_label.shape)\n","print(labels)"]},{"cell_type":"code","execution_count":5,"id":"859a125b","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.147Z"},"id":"859a125b","executionInfo":{"status":"ok","timestamp":1639130193760,"user_tz":300,"elapsed":7,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["####################################\n","### hyper params \n","####################################\n","# filters = '\"#$%&()*+,-/:;<=>@[\\\\]^_`{|}~\\t\\n0123465789!.?\\''\n","# MAX_NB_WORDS_ratio = 0.95\n","# MAX_DOC_LEN_ratio = 0.99\n","# MAX_NB_WORDS = eda_MAX_NB_WORDS(train_text, ratio=MAX_NB_WORDS_ratio, char_level=False, filters=filters)\n","# MAX_DOC_LEN = eda_MAX_DOC_LEN(train_text, ratio=MAX_DOC_LEN_ratio, char_level=False, filters=filters)"]},{"cell_type":"code","source":["# X_train, X_test, word_to_idx, tfidf_vect = tfidf_vectorizer(train_text, test_text, stop_words=True, binary=True, min_df=5)\n","# X_train, transform_mapper = dimension_reduction(X_train, out_dim=1000) # not allow negative \n","# X_test = transform_mapper.transform(X_test)"],"metadata":{"id":"JnQpGP-FR6x9","executionInfo":{"status":"ok","timestamp":1639130193760,"user_tz":300,"elapsed":6,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"id":"JnQpGP-FR6x9","execution_count":6,"outputs":[]},{"cell_type":"markdown","id":"fd1183b7","metadata":{"id":"fd1183b7"},"source":["## extra one-hot features"]},{"cell_type":"code","execution_count":7,"id":"b51f5083","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.239Z"},"id":"b51f5083","scrolled":true,"executionInfo":{"status":"ok","timestamp":1639130193760,"user_tz":300,"elapsed":6,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["# one_hot_X_train, one_hot_X_test, one_hot_word_to_idx, one_hot_count_vect = count_vectorizer(\n","#     train['Subject']+\" \" + train['Organization'], test['Subject']+\" \" + test['Organization'], stop_words=True, binary=False, min_df=3, max_df=0.001)"]},{"cell_type":"markdown","id":"269d56d2","metadata":{"ExecuteTime":{"end_time":"2021-12-10T01:43:16.717443Z","start_time":"2021-12-10T01:43:16.706441Z"},"id":"269d56d2"},"source":["## extra keywords"]},{"cell_type":"code","execution_count":8,"id":"a50842dc","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.275Z"},"id":"a50842dc","executionInfo":{"status":"ok","timestamp":1639130193761,"user_tz":300,"elapsed":7,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["# label_docs = train.groupby('label')['text'].apply(lambda x: \" \".join(x)) # 要去除标点符号\n","# dtm, _, label_word_to_idx, _ = count_vectorizer(label_docs, [''], stop_words=True, min_df=1, binary=True)\n","# label_idx_to_word = dict([val, key] for key, val in label_word_to_idx.items())\n","# keywords_threshold = 1\n","# keywords_idx = np.where(dtm.sum(axis=0)<=keywords_threshold)[0]\n","# print(\" keywords_idx shape: \")\n","# voc = [label_idx_to_word[idx] for idx in keywords_idx]\n","\n","# keywords_X_train, keywords_X_test, keywords_word_to_idx, keywords_count_vect = count_vectorizer(\n","#     train['text'], test['text'], voc=voc, stop_words=True, min_df=1, binary=True)"]},{"cell_type":"code","execution_count":9,"id":"b9a938ba","metadata":{"ExecuteTime":{"start_time":"2021-12-10T02:09:53.312Z"},"id":"b9a938ba","executionInfo":{"status":"ok","timestamp":1639130193761,"user_tz":300,"elapsed":7,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["# _X_train = np.hstack([X_train])\n","# _X_test = np.hstack([X_test])\n","# _X_train = np.hstack([X_train, one_hot_X_train, keywords_X_train])\n","# _X_test = np.hstack([X_test, one_hot_X_test, keywords_X_test])"]},{"cell_type":"markdown","id":"2dc232d5","metadata":{"id":"2dc232d5"},"source":["# BERT"]},{"cell_type":"code","execution_count":10,"id":"d8350e74","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:40:11.072229Z","start_time":"2021-12-10T02:40:11.065229Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"d8350e74","executionInfo":{"status":"ok","timestamp":1639130200560,"user_tz":300,"elapsed":6805,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"f3064f13-17aa-4e3e-bc5b-16c9d24c974b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.5.4)\n","Append path:  /content/drive/My Drive/Text-Classification/code/bert_utils\n","My Linux system:  Linux\n","using:  cuda\n","My Linux system:  Linux\n","using:  cuda\n"]}],"source":["!pip install transformers\n","!pip install torchinfo\n","import torch\n","import torch.nn.functional as F\n","\n","from torchinfo import summary\n","from transformers import BertTokenizer, BertModel, AdamW, BertConfig, get_linear_schedule_with_warmup\n","\n","from bert_utils.training_utils import extract_contextual_embedding, train_multi_label_model, model_eval\n","from bert_utils.data_loader import  data_loader_BERT\n","from bert_utils import glovar \n","from bert_utils.model import *"]},{"cell_type":"code","source":["train_one_hot_labels = F.one_hot(torch.tensor(y_train.values))\n","test_one_hot_labels = F.one_hot(torch.tensor(test_label.values))"],"metadata":{"id":"aRfQroUrnRGp","executionInfo":{"status":"ok","timestamp":1639130200561,"user_tz":300,"elapsed":10,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"id":"aRfQroUrnRGp","execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"id":"621349ed","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:40:15.647445Z","start_time":"2021-12-10T02:40:13.586174Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"621349ed","executionInfo":{"status":"ok","timestamp":1639130208205,"user_tz":300,"elapsed":7653,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"3d66aa72-33a2-4183-f050-ee5f867bfd52"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["cuda:0\n"]},{"output_type":"execute_result","data":{"text/plain":["===========================================================================\n","Layer (type:depth-idx)                             Param #\n","===========================================================================\n","BertModel                                          --\n","├─BertEmbeddings: 1-1                              --\n","│    └─Embedding: 2-1                              23,440,896\n","│    └─Embedding: 2-2                              393,216\n","│    └─Embedding: 2-3                              1,536\n","│    └─LayerNorm: 2-4                              1,536\n","│    └─Dropout: 2-5                                --\n","├─BertEncoder: 1-2                                 --\n","│    └─ModuleList: 2-6                             --\n","│    │    └─BertLayer: 3-1                         7,087,872\n","│    │    └─BertLayer: 3-2                         7,087,872\n","│    │    └─BertLayer: 3-3                         7,087,872\n","│    │    └─BertLayer: 3-4                         7,087,872\n","│    │    └─BertLayer: 3-5                         7,087,872\n","│    │    └─BertLayer: 3-6                         7,087,872\n","│    │    └─BertLayer: 3-7                         7,087,872\n","│    │    └─BertLayer: 3-8                         7,087,872\n","│    │    └─BertLayer: 3-9                         7,087,872\n","│    │    └─BertLayer: 3-10                        7,087,872\n","│    │    └─BertLayer: 3-11                        7,087,872\n","│    │    └─BertLayer: 3-12                        7,087,872\n","├─BertPooler: 1-3                                  --\n","│    └─Linear: 2-7                                 590,592\n","│    └─Tanh: 2-8                                   --\n","===========================================================================\n","Total params: 109,482,240\n","Trainable params: 109,482,240\n","Non-trainable params: 0\n","==========================================================================="]},"metadata":{},"execution_count":12}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_attentions = True, output_hidden_states = True)\n","# global device\n","device = glovar.device_type\n","bert_model = bert_model.to(device)\n","print(next(bert_model.parameters()).device)  # 输出：cpu\n","summary(bert_model)"]},{"cell_type":"code","execution_count":13,"id":"d9f6a91a","metadata":{"id":"d9f6a91a","executionInfo":{"status":"ok","timestamp":1639130208206,"user_tz":300,"elapsed":10,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"outputs":[],"source":["load_embed= True\n","\n","learning_rate = 0.0001\n","epochs = 80\n","patience = 60\n","MAX_DOC_LEN = 200\n","batch_size=32\n","\n","\n","max_len = min(512, MAX_DOC_LEN)\n","label_size = 20\n","label_cols = labels\n","embed_dim = 768\n","hidden_units = 64\n","num_filters = 30\n","kernel_sizes = [1,2,3]"]},{"cell_type":"code","source":["if load_embed is True:\n","    train_sentences_encoding = np.load('train_sentences_encoding.npy')# , mmap_mode='r')\n","    train_input_ids = np.load('train_input_ids.npy')#, mmap_mode='r')\n","    train_sentences_encoding = torch.tensor(train_sentences_encoding)\n","    train_input_ids = torch.tensor(train_input_ids)\n","else:\n","    train_input_ids, train_sentences_encoding = extract_contextual_embedding(train_text, tokenizer, bert_model, max_len = max_len, low_RAM_inner_batch=True)\n","    # train_input_ids, train_sentences_encoding = extract_contextual_embedding(train_text.iloc[1:3], tokenizer, bert_model, max_len = max_len, low_RAM_inner_batch=False) test\n","    np.save('train_sentences_encoding.npy', train_sentences_encoding)\n","    np.save('train_input_ids.npy', train_input_ids)\n","\n","\n","dataloader, validation_dataloader = data_loader_BERT(train_sentences_encoding, train_input_ids, train_one_hot_labels, batch_size, random_state=1234, test_size=0.1)\n","del train_sentences_encoding, train_input_ids"],"metadata":{"id":"OJLMUVgVYema","executionInfo":{"status":"ok","timestamp":1639130208207,"user_tz":300,"elapsed":10,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"id":"OJLMUVgVYema","execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":15,"id":"6eb114c3","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:40:50.115095Z","start_time":"2021-12-10T02:40:50.102096Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"6eb114c3","executionInfo":{"status":"ok","timestamp":1639130208461,"user_tz":300,"elapsed":6,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"013d131a-6a40-4d69-cb4b-6cb70949feab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["clf_naive(\n","  (fc): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=768, out_features=384, bias=True)\n","    (2): ReLU()\n","    (3): Dropout(p=0.0, inplace=False)\n","    (4): Linear(in_features=384, out_features=192, bias=True)\n","    (5): ReLU()\n","    (6): Dropout(p=0.0, inplace=False)\n","    (7): Linear(in_features=192, out_features=64, bias=True)\n","    (8): ReLU()\n","    (9): Dropout(p=0.0, inplace=False)\n","    (10): Linear(in_features=64, out_features=20, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":15}],"source":["model_path = 'bert_clf'\n","label_size = len(labels)\n","# model = lstm_cnn_o1(embed_dim, max_len, hidden_units, num_filters, kernel_sizes, label_size)\n","# model = lstm_cnn_o2(embed_dim, max_len, hidden_units, num_filters, kernel_sizes, label_size)\n","# model = clf(embed_dim, max_len, hidden_units, label_size)\n","model = clf_naive(embed_dim, max_len, hidden_units, label_size, dropout_rate=0.0)\n","model.to(device)"]},{"cell_type":"code","source":["[torch.cuda.empty_cache() for _ in range(10) ]\n","print(torch.cuda.memory_summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y75AD5TEun3D","executionInfo":{"status":"ok","timestamp":1639130208461,"user_tz":300,"elapsed":6,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}},"outputId":"4ba9d93b-6feb-4034-8630-741c9f7ff0f9"},"id":"y75AD5TEun3D","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["|===========================================================================|\n","|                  PyTorch CUDA memory summary, device ID 0                 |\n","|---------------------------------------------------------------------------|\n","|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n","|===========================================================================|\n","|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n","|---------------------------------------------------------------------------|\n","| Allocated memory      |  431171 KB |  431171 KB |  431171 KB |       0 B  |\n","|       from large pool |  430336 KB |  430336 KB |  430336 KB |       0 B  |\n","|       from small pool |     835 KB |     835 KB |     835 KB |       0 B  |\n","|---------------------------------------------------------------------------|\n","| Active memory         |  431171 KB |  431171 KB |  431171 KB |       0 B  |\n","|       from large pool |  430336 KB |  430336 KB |  430336 KB |       0 B  |\n","|       from small pool |     835 KB |     835 KB |     835 KB |       0 B  |\n","|---------------------------------------------------------------------------|\n","| GPU reserved memory   |  483328 KB |  483328 KB |  483328 KB |       0 B  |\n","|       from large pool |  481280 KB |  481280 KB |  481280 KB |       0 B  |\n","|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\n","|---------------------------------------------------------------------------|\n","| Non-releasable memory |   52156 KB |   54552 KB |  265210 KB |  213053 KB |\n","|       from large pool |   50944 KB |   52992 KB |  263168 KB |  212224 KB |\n","|       from small pool |    1212 KB |    2042 KB |    2042 KB |     829 KB |\n","|---------------------------------------------------------------------------|\n","| Allocations           |     209    |     209    |     209    |       0    |\n","|       from large pool |      76    |      76    |      76    |       0    |\n","|       from small pool |     133    |     133    |     133    |       0    |\n","|---------------------------------------------------------------------------|\n","| Active allocs         |     209    |     209    |     209    |       0    |\n","|       from large pool |      76    |      76    |      76    |       0    |\n","|       from small pool |     133    |     133    |     133    |       0    |\n","|---------------------------------------------------------------------------|\n","| GPU reserved segments |      21    |      21    |      21    |       0    |\n","|       from large pool |      20    |      20    |      20    |       0    |\n","|       from small pool |       1    |       1    |       1    |       0    |\n","|---------------------------------------------------------------------------|\n","| Non-releasable allocs |      18    |      19    |      20    |       2    |\n","|       from large pool |      17    |      18    |      19    |       2    |\n","|       from small pool |       1    |       1    |       1    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize allocations  |       0    |       0    |       0    |       0    |\n","|---------------------------------------------------------------------------|\n","| Oversize GPU segments |       0    |       0    |       0    |       0    |\n","|===========================================================================|\n","\n"]}]},{"cell_type":"code","execution_count":null,"id":"0f1f862a","metadata":{"ExecuteTime":{"end_time":"2021-12-10T02:41:35.524180Z","start_time":"2021-12-10T02:41:35.498181Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"0f1f862a","outputId":"915c3641-258a-46a6-b621-29afe6b3dace"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","\n","======== Epoch 1 / 80 ========\n","Training...\n","    Epoch 1\t Train Loss: 2.9950\t Train Acc: 0.0521\t Train F1: 0.0055\t Train AUC: 0.5965\t Train precision: 0.0056\t Train recall: 0.0500\n","    Epoch 1\t Val Loss: 2.9951\t Val Acc: 0.0523\t Val F1: 0.0050\t Val AUC: 0.5942\t Val precision: 0.0026\t Val recall: 0.0500\n","model saved\n","\n","======== Epoch 2 / 80 ========\n","Training...\n","    Epoch 2\t Train Loss: 2.9925\t Train Acc: 0.0740\t Train F1: 0.0125\t Train AUC: 0.6036\t Train precision: 0.0374\t Train recall: 0.0532\n","    Epoch 2\t Val Loss: 2.9923\t Val Acc: 0.0775\t Val F1: 0.0152\t Val AUC: 0.6211\t Val precision: 0.0109\t Val recall: 0.0570\n","model saved\n","\n","======== Epoch 3 / 80 ========\n","Training...\n","    Epoch 3\t Train Loss: 2.9851\t Train Acc: 0.0824\t Train F1: 0.0168\t Train AUC: 0.5856\t Train precision: 0.0181\t Train recall: 0.0615\n","    Epoch 3\t Val Loss: 2.9841\t Val Acc: 0.0866\t Val F1: 0.0189\t Val AUC: 0.5936\t Val precision: 0.0124\t Val recall: 0.0657\n","\n","======== Epoch 4 / 80 ========\n","Training...\n","    Epoch 4\t Train Loss: 2.9754\t Train Acc: 0.0939\t Train F1: 0.0176\t Train AUC: 0.5963\t Train precision: 0.0100\t Train recall: 0.0755\n","    Epoch 4\t Val Loss: 2.9730\t Val Acc: 0.0938\t Val F1: 0.0180\t Val AUC: 0.6057\t Val precision: 0.0103\t Val recall: 0.0761\n","\n","======== Epoch 5 / 80 ========\n","Training...\n","    Epoch 5\t Train Loss: 2.9683\t Train Acc: 0.0982\t Train F1: 0.0184\t Train AUC: 0.6279\t Train precision: 0.0105\t Train recall: 0.0788\n","    Epoch 5\t Val Loss: 2.9663\t Val Acc: 0.0974\t Val F1: 0.0186\t Val AUC: 0.6361\t Val precision: 0.0106\t Val recall: 0.0787\n","model saved\n","\n","======== Epoch 6 / 80 ========\n","Training...\n","    Epoch 6\t Train Loss: 2.9566\t Train Acc: 0.1011\t Train F1: 0.0191\t Train AUC: 0.6247\t Train precision: 0.0174\t Train recall: 0.0830\n","    Epoch 6\t Val Loss: 2.9580\t Val Acc: 0.0992\t Val F1: 0.0217\t Val AUC: 0.6269\t Val precision: 0.0264\t Val recall: 0.0818\n","\n","======== Epoch 7 / 80 ========\n","Training...\n","    Epoch 7\t Train Loss: 2.9305\t Train Acc: 0.1386\t Train F1: 0.0533\t Train AUC: 0.6818\t Train precision: 0.0501\t Train recall: 0.1146\n","    Epoch 7\t Val Loss: 2.9314\t Val Acc: 0.1416\t Val F1: 0.0577\t Val AUC: 0.6878\t Val precision: 0.0502\t Val recall: 0.1184\n","model saved\n","\n","======== Epoch 8 / 80 ========\n","Training...\n","    Epoch 8\t Train Loss: 2.9091\t Train Acc: 0.1681\t Train F1: 0.0724\t Train AUC: 0.7024\t Train precision: 0.0857\t Train recall: 0.1469\n","    Epoch 8\t Val Loss: 2.9138\t Val Acc: 0.1560\t Val F1: 0.0658\t Val AUC: 0.6996\t Val precision: 0.0789\t Val recall: 0.1372\n","model saved\n","\n","======== Epoch 9 / 80 ========\n","Training...\n","    Epoch 9\t Train Loss: 2.8856\t Train Acc: 0.1855\t Train F1: 0.0785\t Train AUC: 0.7270\t Train precision: 0.0813\t Train recall: 0.1608\n","    Epoch 9\t Val Loss: 2.8922\t Val Acc: 0.1858\t Val F1: 0.0756\t Val AUC: 0.7312\t Val precision: 0.0673\t Val recall: 0.1617\n","model saved\n","\n","======== Epoch 10 / 80 ========\n","Training...\n","    Epoch 10\t Train Loss: 2.8618\t Train Acc: 0.2290\t Train F1: 0.1178\t Train AUC: 0.7401\t Train precision: 0.0989\t Train recall: 0.2015\n","    Epoch 10\t Val Loss: 2.8721\t Val Acc: 0.2164\t Val F1: 0.1093\t Val AUC: 0.7396\t Val precision: 0.0960\t Val recall: 0.1910\n","model saved\n","\n","======== Epoch 11 / 80 ========\n","Training...\n","    Epoch 11\t Train Loss: 2.8529\t Train Acc: 0.2295\t Train F1: 0.1260\t Train AUC: 0.7573\t Train precision: 0.1411\t Train recall: 0.2011\n","    Epoch 11\t Val Loss: 2.8600\t Val Acc: 0.2362\t Val F1: 0.1314\t Val AUC: 0.7566\t Val precision: 0.1096\t Val recall: 0.2081\n","model saved\n","\n","======== Epoch 12 / 80 ========\n","Training...\n","    Epoch 12\t Train Loss: 2.8277\t Train Acc: 0.2615\t Train F1: 0.1414\t Train AUC: 0.7584\t Train precision: 0.1058\t Train recall: 0.2315\n","    Epoch 12\t Val Loss: 2.8368\t Val Acc: 0.2579\t Val F1: 0.1403\t Val AUC: 0.7589\t Val precision: 0.1055\t Val recall: 0.2294\n","model saved\n","\n","======== Epoch 13 / 80 ========\n","Training...\n","    Epoch 13\t Train Loss: 2.8213\t Train Acc: 0.2637\t Train F1: 0.1419\t Train AUC: 0.7422\t Train precision: 0.1187\t Train recall: 0.2341\n","    Epoch 13\t Val Loss: 2.8305\t Val Acc: 0.2579\t Val F1: 0.1376\t Val AUC: 0.7419\t Val precision: 0.1011\t Val recall: 0.2295\n","\n","======== Epoch 14 / 80 ========\n","Training...\n","    Epoch 14\t Train Loss: 2.8144\t Train Acc: 0.2642\t Train F1: 0.1449\t Train AUC: 0.7624\t Train precision: 0.1172\t Train recall: 0.2346\n","    Epoch 14\t Val Loss: 2.8245\t Val Acc: 0.2579\t Val F1: 0.1395\t Val AUC: 0.7607\t Val precision: 0.1312\t Val recall: 0.2295\n","model saved\n","\n","======== Epoch 15 / 80 ========\n","Training...\n","    Epoch 15\t Train Loss: 2.7976\t Train Acc: 0.2837\t Train F1: 0.1602\t Train AUC: 0.7637\t Train precision: 0.1276\t Train recall: 0.2543\n","    Epoch 15\t Val Loss: 2.8073\t Val Acc: 0.2723\t Val F1: 0.1508\t Val AUC: 0.7630\t Val precision: 0.1152\t Val recall: 0.2448\n","model saved\n","\n","======== Epoch 16 / 80 ========\n","Training...\n","    Epoch 16\t Train Loss: 2.7860\t Train Acc: 0.2942\t Train F1: 0.1699\t Train AUC: 0.7663\t Train precision: 0.1324\t Train recall: 0.2629\n","    Epoch 16\t Val Loss: 2.7952\t Val Acc: 0.2885\t Val F1: 0.1678\t Val AUC: 0.7658\t Val precision: 0.1540\t Val recall: 0.2588\n","model saved\n","\n","======== Epoch 17 / 80 ========\n","Training...\n","    Epoch 17\t Train Loss: 2.7798\t Train Acc: 0.3020\t Train F1: 0.1771\t Train AUC: 0.7674\t Train precision: 0.1626\t Train recall: 0.2689\n","    Epoch 17\t Val Loss: 2.7879\t Val Acc: 0.2931\t Val F1: 0.1716\t Val AUC: 0.7657\t Val precision: 0.1554\t Val recall: 0.2613\n","\n","======== Epoch 18 / 80 ========\n","Training...\n","    Epoch 18\t Train Loss: 2.7712\t Train Acc: 0.3110\t Train F1: 0.1821\t Train AUC: 0.7751\t Train precision: 0.1634\t Train recall: 0.2774\n","    Epoch 18\t Val Loss: 2.7796\t Val Acc: 0.3003\t Val F1: 0.1754\t Val AUC: 0.7738\t Val precision: 0.1490\t Val recall: 0.2681\n","model saved\n","\n","======== Epoch 19 / 80 ========\n","Training...\n","    Epoch 19\t Train Loss: 2.7649\t Train Acc: 0.3164\t Train F1: 0.1859\t Train AUC: 0.7704\t Train precision: 0.1571\t Train recall: 0.2826\n","    Epoch 19\t Val Loss: 2.7742\t Val Acc: 0.3093\t Val F1: 0.1841\t Val AUC: 0.7679\t Val precision: 0.1549\t Val recall: 0.2771\n","\n","======== Epoch 20 / 80 ========\n","Training...\n","    Epoch 20\t Train Loss: 2.7560\t Train Acc: 0.3316\t Train F1: 0.2026\t Train AUC: 0.7716\t Train precision: 0.1674\t Train recall: 0.2980\n","    Epoch 20\t Val Loss: 2.7656\t Val Acc: 0.3210\t Val F1: 0.1958\t Val AUC: 0.7697\t Val precision: 0.1626\t Val recall: 0.2897\n","\n","======== Epoch 21 / 80 ========\n","Training...\n","    Epoch 21\t Train Loss: 2.7484\t Train Acc: 0.3349\t Train F1: 0.2059\t Train AUC: 0.7856\t Train precision: 0.1723\t Train recall: 0.3005\n","    Epoch 21\t Val Loss: 2.7575\t Val Acc: 0.3255\t Val F1: 0.2017\t Val AUC: 0.7822\t Val precision: 0.1740\t Val recall: 0.2931\n","model saved\n","\n","======== Epoch 22 / 80 ========\n","Training...\n","    Epoch 22\t Train Loss: 2.7518\t Train Acc: 0.3334\t Train F1: 0.2178\t Train AUC: 0.7841\t Train precision: 0.1899\t Train recall: 0.3004\n","    Epoch 22\t Val Loss: 2.7560\t Val Acc: 0.3264\t Val F1: 0.2115\t Val AUC: 0.7823\t Val precision: 0.1906\t Val recall: 0.2949\n","model saved\n","\n","======== Epoch 23 / 80 ========\n","Training...\n","    Epoch 23\t Train Loss: 2.7377\t Train Acc: 0.3482\t Train F1: 0.2192\t Train AUC: 0.7851\t Train precision: 0.1815\t Train recall: 0.3136\n","    Epoch 23\t Val Loss: 2.7475\t Val Acc: 0.3381\t Val F1: 0.2114\t Val AUC: 0.7821\t Val precision: 0.1741\t Val recall: 0.3058\n","\n","======== Epoch 24 / 80 ========\n","Training...\n","    Epoch 24\t Train Loss: 2.7335\t Train Acc: 0.3518\t Train F1: 0.2293\t Train AUC: 0.7985\t Train precision: 0.2116\t Train recall: 0.3168\n","    Epoch 24\t Val Loss: 2.7437\t Val Acc: 0.3481\t Val F1: 0.2283\t Val AUC: 0.7966\t Val precision: 0.1930\t Val recall: 0.3145\n","model saved\n","\n","======== Epoch 25 / 80 ========\n","Training...\n","    Epoch 25\t Train Loss: 2.7232\t Train Acc: 0.3597\t Train F1: 0.2236\t Train AUC: 0.7966\t Train precision: 0.1852\t Train recall: 0.3237\n","    Epoch 25\t Val Loss: 2.7367\t Val Acc: 0.3490\t Val F1: 0.2188\t Val AUC: 0.7942\t Val precision: 0.1963\t Val recall: 0.3153\n","\n","======== Epoch 26 / 80 ========\n","Training...\n","    Epoch 26\t Train Loss: 2.7387\t Train Acc: 0.3415\t Train F1: 0.2224\t Train AUC: 0.7914\t Train precision: 0.2084\t Train recall: 0.3081\n","    Epoch 26\t Val Loss: 2.7482\t Val Acc: 0.3228\t Val F1: 0.2049\t Val AUC: 0.7898\t Val precision: 0.1738\t Val recall: 0.2920\n","\n","======== Epoch 27 / 80 ========\n","Training...\n","    Epoch 27\t Train Loss: 2.7183\t Train Acc: 0.3640\t Train F1: 0.2359\t Train AUC: 0.8022\t Train precision: 0.2082\t Train recall: 0.3276\n","    Epoch 27\t Val Loss: 2.7316\t Val Acc: 0.3417\t Val F1: 0.2195\t Val AUC: 0.7994\t Val precision: 0.1868\t Val recall: 0.3084\n","model saved\n","\n","======== Epoch 28 / 80 ========\n","Training...\n","    Epoch 28\t Train Loss: 2.7169\t Train Acc: 0.3645\t Train F1: 0.2374\t Train AUC: 0.8082\t Train precision: 0.2010\t Train recall: 0.3277\n","    Epoch 28\t Val Loss: 2.7280\t Val Acc: 0.3490\t Val F1: 0.2261\t Val AUC: 0.8051\t Val precision: 0.1870\t Val recall: 0.3144\n","model saved\n","\n","======== Epoch 29 / 80 ========\n","Training...\n","    Epoch 29\t Train Loss: 2.7069\t Train Acc: 0.3752\t Train F1: 0.2475\t Train AUC: 0.8069\t Train precision: 0.2148\t Train recall: 0.3378\n","    Epoch 29\t Val Loss: 2.7217\t Val Acc: 0.3571\t Val F1: 0.2337\t Val AUC: 0.8034\t Val precision: 0.1950\t Val recall: 0.3224\n","\n","======== Epoch 30 / 80 ========\n","Training...\n","    Epoch 30\t Train Loss: 2.7082\t Train Acc: 0.3775\t Train F1: 0.2456\t Train AUC: 0.7982\t Train precision: 0.2183\t Train recall: 0.3412\n","    Epoch 30\t Val Loss: 2.7189\t Val Acc: 0.3661\t Val F1: 0.2382\t Val AUC: 0.7957\t Val precision: 0.1925\t Val recall: 0.3321\n","\n","======== Epoch 31 / 80 ========\n","Training...\n","    Epoch 31\t Train Loss: 2.7017\t Train Acc: 0.3802\t Train F1: 0.2484\t Train AUC: 0.8122\t Train precision: 0.2213\t Train recall: 0.3422\n","    Epoch 31\t Val Loss: 2.7157\t Val Acc: 0.3652\t Val F1: 0.2376\t Val AUC: 0.8089\t Val precision: 0.1927\t Val recall: 0.3295\n","model saved\n","\n","======== Epoch 32 / 80 ========\n","Training...\n","    Epoch 32\t Train Loss: 2.6984\t Train Acc: 0.3855\t Train F1: 0.2563\t Train AUC: 0.8096\t Train precision: 0.2175\t Train recall: 0.3482\n","    Epoch 32\t Val Loss: 2.7127\t Val Acc: 0.3724\t Val F1: 0.2481\t Val AUC: 0.8068\t Val precision: 0.2018\t Val recall: 0.3378\n","\n","======== Epoch 33 / 80 ========\n","Training...\n","    Epoch 33\t Train Loss: 2.7001\t Train Acc: 0.3834\t Train F1: 0.2518\t Train AUC: 0.8007\t Train precision: 0.2225\t Train recall: 0.3454\n","    Epoch 33\t Val Loss: 2.7152\t Val Acc: 0.3634\t Val F1: 0.2387\t Val AUC: 0.7972\t Val precision: 0.1952\t Val recall: 0.3285\n","\n","======== Epoch 34 / 80 ========\n","Training...\n","    Epoch 34\t Train Loss: 2.6876\t Train Acc: 0.4005\t Train F1: 0.2697\t Train AUC: 0.8187\t Train precision: 0.2397\t Train recall: 0.3614\n","    Epoch 34\t Val Loss: 2.7056\t Val Acc: 0.3832\t Val F1: 0.2579\t Val AUC: 0.8149\t Val precision: 0.2119\t Val recall: 0.3464\n","model saved\n","\n","======== Epoch 35 / 80 ========\n","Training...\n","    Epoch 35\t Train Loss: 2.6863\t Train Acc: 0.4014\t Train F1: 0.2693\t Train AUC: 0.8188\t Train precision: 0.2263\t Train recall: 0.3620\n","    Epoch 35\t Val Loss: 2.7027\t Val Acc: 0.3850\t Val F1: 0.2605\t Val AUC: 0.8146\t Val precision: 0.2232\t Val recall: 0.3485\n","\n","======== Epoch 36 / 80 ========\n","Training...\n","    Epoch 36\t Train Loss: 2.6817\t Train Acc: 0.4029\t Train F1: 0.2663\t Train AUC: 0.8224\t Train precision: 0.2241\t Train recall: 0.3636\n","    Epoch 36\t Val Loss: 2.6993\t Val Acc: 0.3832\t Val F1: 0.2513\t Val AUC: 0.8194\t Val precision: 0.2065\t Val recall: 0.3462\n","model saved\n","\n","======== Epoch 37 / 80 ========\n","Training...\n","    Epoch 37\t Train Loss: 2.6786\t Train Acc: 0.4065\t Train F1: 0.2671\t Train AUC: 0.8225\t Train precision: 0.2237\t Train recall: 0.3676\n","    Epoch 37\t Val Loss: 2.6949\t Val Acc: 0.3832\t Val F1: 0.2515\t Val AUC: 0.8199\t Val precision: 0.2096\t Val recall: 0.3474\n","model saved\n","\n","======== Epoch 38 / 80 ========\n","Training...\n","    Epoch 38\t Train Loss: 2.6771\t Train Acc: 0.4081\t Train F1: 0.2690\t Train AUC: 0.8220\t Train precision: 0.2277\t Train recall: 0.3690\n","    Epoch 38\t Val Loss: 2.6954\t Val Acc: 0.3841\t Val F1: 0.2517\t Val AUC: 0.8199\t Val precision: 0.2293\t Val recall: 0.3481\n","model saved\n","\n","======== Epoch 39 / 80 ========\n","Training...\n","    Epoch 39\t Train Loss: 2.6751\t Train Acc: 0.4079\t Train F1: 0.2712\t Train AUC: 0.8266\t Train precision: 0.2395\t Train recall: 0.3688\n","    Epoch 39\t Val Loss: 2.6932\t Val Acc: 0.3859\t Val F1: 0.2562\t Val AUC: 0.8234\t Val precision: 0.2197\t Val recall: 0.3495\n","model saved\n","\n","======== Epoch 40 / 80 ========\n","Training...\n","    Epoch 40\t Train Loss: 2.6828\t Train Acc: 0.3984\t Train F1: 0.2645\t Train AUC: 0.8218\t Train precision: 0.2527\t Train recall: 0.3607\n","    Epoch 40\t Val Loss: 2.7016\t Val Acc: 0.3697\t Val F1: 0.2446\t Val AUC: 0.8204\t Val precision: 0.2110\t Val recall: 0.3356\n","\n","======== Epoch 41 / 80 ========\n","Training...\n","    Epoch 41\t Train Loss: 2.6694\t Train Acc: 0.4120\t Train F1: 0.2707\t Train AUC: 0.8291\t Train precision: 0.2343\t Train recall: 0.3727\n","    Epoch 41\t Val Loss: 2.6880\t Val Acc: 0.3904\t Val F1: 0.2570\t Val AUC: 0.8279\t Val precision: 0.2243\t Val recall: 0.3537\n","model saved\n","\n","======== Epoch 42 / 80 ========\n","Training...\n","    Epoch 42\t Train Loss: 2.6709\t Train Acc: 0.4131\t Train F1: 0.2955\t Train AUC: 0.8355\t Train precision: 0.2659\t Train recall: 0.3738\n","    Epoch 42\t Val Loss: 2.6883\t Val Acc: 0.3977\t Val F1: 0.2847\t Val AUC: 0.8340\t Val precision: 0.2549\t Val recall: 0.3598\n","model saved\n","\n","======== Epoch 43 / 80 ========\n","Training...\n","    Epoch 43\t Train Loss: 2.6570\t Train Acc: 0.4300\t Train F1: 0.3039\t Train AUC: 0.8380\t Train precision: 0.2781\t Train recall: 0.3909\n","    Epoch 43\t Val Loss: 2.6735\t Val Acc: 0.4076\t Val F1: 0.2892\t Val AUC: 0.8379\t Val precision: 0.2604\t Val recall: 0.3707\n","model saved\n","\n","======== Epoch 44 / 80 ========\n","Training...\n","    Epoch 44\t Train Loss: 2.6536\t Train Acc: 0.4322\t Train F1: 0.3031\t Train AUC: 0.8318\t Train precision: 0.2777\t Train recall: 0.3923\n","    Epoch 44\t Val Loss: 2.6735\t Val Acc: 0.4031\t Val F1: 0.2816\t Val AUC: 0.8304\t Val precision: 0.2856\t Val recall: 0.3660\n","\n","======== Epoch 45 / 80 ========\n","Training...\n","    Epoch 45\t Train Loss: 2.6476\t Train Acc: 0.4386\t Train F1: 0.3136\t Train AUC: 0.8338\t Train precision: 0.2781\t Train recall: 0.3991\n","    Epoch 45\t Val Loss: 2.6665\t Val Acc: 0.4166\t Val F1: 0.2982\t Val AUC: 0.8319\t Val precision: 0.2551\t Val recall: 0.3793\n","\n","======== Epoch 46 / 80 ========\n","Training...\n","    Epoch 46\t Train Loss: 2.6498\t Train Acc: 0.4380\t Train F1: 0.3158\t Train AUC: 0.8361\t Train precision: 0.3006\t Train recall: 0.3986\n","    Epoch 46\t Val Loss: 2.6714\t Val Acc: 0.4130\t Val F1: 0.2981\t Val AUC: 0.8356\t Val precision: 0.2554\t Val recall: 0.3764\n","\n","======== Epoch 47 / 80 ========\n","Training...\n","    Epoch 47\t Train Loss: 2.6518\t Train Acc: 0.4328\t Train F1: 0.3093\t Train AUC: 0.8293\t Train precision: 0.2832\t Train recall: 0.3929\n","    Epoch 47\t Val Loss: 2.6729\t Val Acc: 0.4085\t Val F1: 0.2915\t Val AUC: 0.8272\t Val precision: 0.2642\t Val recall: 0.3708\n","\n","======== Epoch 48 / 80 ========\n","Training...\n","    Epoch 48\t Train Loss: 2.6566\t Train Acc: 0.4267\t Train F1: 0.3051\t Train AUC: 0.8236\t Train precision: 0.2846\t Train recall: 0.3875\n","    Epoch 48\t Val Loss: 2.6767\t Val Acc: 0.4130\t Val F1: 0.2983\t Val AUC: 0.8226\t Val precision: 0.2854\t Val recall: 0.3762\n","\n","======== Epoch 49 / 80 ========\n","Training...\n","    Epoch 49\t Train Loss: 2.6464\t Train Acc: 0.4451\t Train F1: 0.3260\t Train AUC: 0.8369\t Train precision: 0.3020\t Train recall: 0.4063\n","    Epoch 49\t Val Loss: 2.6652\t Val Acc: 0.4139\t Val F1: 0.3036\t Val AUC: 0.8348\t Val precision: 0.2639\t Val recall: 0.3783\n","\n","======== Epoch 50 / 80 ========\n","Training...\n","    Epoch 50\t Train Loss: 2.6412\t Train Acc: 0.4454\t Train F1: 0.3191\t Train AUC: 0.8368\t Train precision: 0.3083\t Train recall: 0.4052\n","    Epoch 50\t Val Loss: 2.6620\t Val Acc: 0.4184\t Val F1: 0.3009\t Val AUC: 0.8359\t Val precision: 0.2576\t Val recall: 0.3814\n","\n","======== Epoch 51 / 80 ========\n","Training...\n","    Epoch 51\t Train Loss: 2.6393\t Train Acc: 0.4486\t Train F1: 0.3231\t Train AUC: 0.8349\t Train precision: 0.2927\t Train recall: 0.4085\n","    Epoch 51\t Val Loss: 2.6597\t Val Acc: 0.4256\t Val F1: 0.3078\t Val AUC: 0.8323\t Val precision: 0.2904\t Val recall: 0.3878\n","\n","======== Epoch 52 / 80 ========\n","Training...\n","    Epoch 52\t Train Loss: 2.6374\t Train Acc: 0.4498\t Train F1: 0.3238\t Train AUC: 0.8325\t Train precision: 0.3025\t Train recall: 0.4101\n","    Epoch 52\t Val Loss: 2.6595\t Val Acc: 0.4220\t Val F1: 0.3031\t Val AUC: 0.8300\t Val precision: 0.2579\t Val recall: 0.3852\n","\n","======== Epoch 53 / 80 ========\n","Training...\n","    Epoch 53\t Train Loss: 2.6352\t Train Acc: 0.4513\t Train F1: 0.3257\t Train AUC: 0.8363\t Train precision: 0.3008\t Train recall: 0.4110\n","    Epoch 53\t Val Loss: 2.6584\t Val Acc: 0.4292\t Val F1: 0.3099\t Val AUC: 0.8338\t Val precision: 0.2871\t Val recall: 0.3914\n","\n","======== Epoch 54 / 80 ========\n","Training...\n","    Epoch 54\t Train Loss: 2.6380\t Train Acc: 0.4479\t Train F1: 0.3279\t Train AUC: 0.8363\t Train precision: 0.3035\t Train recall: 0.4089\n","    Epoch 54\t Val Loss: 2.6585\t Val Acc: 0.4292\t Val F1: 0.3131\t Val AUC: 0.8336\t Val precision: 0.2895\t Val recall: 0.3921\n","\n","======== Epoch 55 / 80 ========\n","Training...\n","    Epoch 55\t Train Loss: 2.6308\t Train Acc: 0.4565\t Train F1: 0.3322\t Train AUC: 0.8390\t Train precision: 0.3054\t Train recall: 0.4164\n","    Epoch 55\t Val Loss: 2.6511\t Val Acc: 0.4364\t Val F1: 0.3174\t Val AUC: 0.8374\t Val precision: 0.2940\t Val recall: 0.3986\n","\n","======== Epoch 56 / 80 ========\n","Training...\n","    Epoch 56\t Train Loss: 2.6341\t Train Acc: 0.4539\t Train F1: 0.3360\t Train AUC: 0.8435\t Train precision: 0.3234\t Train recall: 0.4134\n","    Epoch 56\t Val Loss: 2.6559\t Val Acc: 0.4310\t Val F1: 0.3181\t Val AUC: 0.8417\t Val precision: 0.2762\t Val recall: 0.3936\n","model saved\n","\n","======== Epoch 57 / 80 ========\n","Training...\n"]}],"source":["model = clf_naive(embed_dim, max_len, hidden_units, label_size, dropout_rate=0.2)\n","model.to(device)\n","\n","# Data Loader\n","\n","optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n","total_steps = len(dataloader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * 0.1), num_training_steps=total_steps)\n","model, training_stats, pred_labels, true_labels = train_multi_label_model(model, label_size, label_cols, dataloader, validation_dataloader, optimizer=optimizer, scheduler=scheduler, epochs=epochs, patience=patience, model_path=model_path)\n","\n","\n","pd.set_option('precision', 2)\n","df_stats = pd.DataFrame(data=training_stats)\n","df_stats = df_stats.set_index('epoch')\n","df_stats.to_csv(model_path[0:-2] + 'csv')\n","\n","import seaborn as sns\n","sns.set(style='darkgrid')\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12, 6)\n","plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n","plt.legend()\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.xticks(list(range(1, epochs + 1)))\n","plt.show()"]},{"cell_type":"code","source":["# model.load_state_dict(torch.load(model_path))"],"metadata":{"id":"flba59bywKcr","executionInfo":{"status":"ok","timestamp":1639130511997,"user_tz":300,"elapsed":940,"user":{"displayName":"Wei Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKFRGCPHBXOIreYY1GgMyIUPCGnToBiaki3_u3=s64","userId":"18154280958911480081"}}},"id":"flba59bywKcr","execution_count":18,"outputs":[]},{"cell_type":"code","source":["if load_embed is True:\n","    test_sentences_encoding = np.load('test_sentences_encoding.npy')#, mmap_mode='r')\n","    test_input_ids = np.load('test_input_ids.npy') # , mmap_mode='r')\n","    test_sentences_encoding = torch.tensor(test_sentences_encoding)\n","    test_input_ids = torch.tensor(test_input_ids)\n","else:\n","    test_input_ids, test_sentences_encoding = extract_contextual_embedding(test_text, tokenizer, bert_model, max_len = max_len, low_RAM_inner_batch=True)\n","    np.save('test_sentences_encoding.npy', test_sentences_encoding)\n","    np.save('test_input_ids.npy', test_input_ids)\n","\n","\n","test_dataloader, _ = data_loader_BERT(test_sentences_encoding,test_input_ids, test_one_hot_labels, testing=True)\n","del test_sentences_encoding, test_input_ids\n","\n","tokenized_texts, pred_labels, true_labels, avg_val_loss, auc_score, precison, recall, acc, f1 = model_eval(model, test_dataloader,  labels , class_weight=None)\n","classification_report = evaluation_report(np.argmax(true_labels, axis=1),  np.argmax(pred_labels, axis=1), labels=labels)\n","roc_auc(y_test, pred_labels)"],"metadata":{"id":"z7axjlu1jF7u"},"id":"z7axjlu1jF7u","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"NN_based_models_BERT_v1_text.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"190.458px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":5}